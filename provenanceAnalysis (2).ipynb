{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ccd9de2-7663-4c6e-9957-9d8d4c12203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82ed68a-20b1-4492-abe5-5c1487ca29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file names to merge\n",
    "file_names = ['Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', 'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', 'Friday-WorkingHours-Morning.pcap_ISCX.csv', 'Monday-WorkingHours.pcap_ISCX.csv', 'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', 'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', 'Tuesday-WorkingHours.pcap_ISCX.csv', 'Wednesday-workingHours.pcap_ISCX.csv']\n",
    "\n",
    "# Create an empty DataFrame to store merged data\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Merge CSV files\n",
    "for filename in file_names:\n",
    "    df = pd.read_csv(filename)\n",
    "    data = pd.concat([data, df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80be0ab2-da3f-4f7d-a0e6-05e4d68d0a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
       "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
       "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
       "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
       "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
       "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
       "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
       "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
       "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
       "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
       "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
       "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
       "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
       "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
       "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
       "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
       "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
       "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
       "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
       "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
       "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
       "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
       "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
       "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
       "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
       "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n",
       "       ' Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5ea813-d3a6-4a8c-8cb7-0fe76c1e1492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 308381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2522362, 79)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups = data[data.duplicated()]\n",
    "print(f'Number of duplicates: {len(dups)}')\n",
    "\n",
    "data.drop_duplicates(inplace = True)\n",
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6ce5c4-80c6-45e6-85ef-8f9c6607ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns by removing leading/trailing whitespace\n",
    "col_names = {col: col.strip() for col in data.columns}\n",
    "data.rename(columns = col_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f1cbba-8911-49e1-a22b-56069a92900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Bytes/s    353\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_val = data.isna().sum()\n",
    "print(missing_val.loc[missing_val > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac419dc-f901-4d94-8f2a-35fcd3e6dce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Bytes/s      1211\n",
      "Flow Packets/s    1564\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for infinity values\n",
    "numeric_cols = data.select_dtypes(include = np.number).columns\n",
    "inf_count = np.isinf(data[numeric_cols]).sum()\n",
    "print(inf_count[inf_count > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c098e1-3fc9-4ac7-8ee4-39b8fa4b990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial missing values: 353\n",
      "Missing values after processing infinite values: 3128\n"
     ]
    }
   ],
   "source": [
    "# Replacing any infinite values (positive or negative) with NaN (not a number)\n",
    "print(f'Initial missing values: {data.isna().sum().sum()}')\n",
    "\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "\n",
    "print(f'Missing values after processing infinite values: {data.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7eaf000-3d1e-4f4d-8e49-b29ee5f7a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Bytes/s      1564\n",
      "Flow Packets/s    1564\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = data.isna().sum()\n",
    "print(missing.loc[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9cfbe3d-9b83-4aee-b624-f88091d0237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values with median\n",
    "med_flow_bytes = data['Flow Bytes/s'].median()\n",
    "med_flow_packets = data['Flow Packets/s'].median()\n",
    "data.fillna({'Flow Bytes/s':med_flow_bytes}, inplace = True)\n",
    "data.fillna({'Flow Packets/s':med_flow_packets}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c33b7fac-7fd3-4ee4-9632-47c8f46bc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Flow Bytes/s' missing values: 0\n",
      "Number of 'Flow Packets/s' missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of \\'Flow Bytes/s\\' missing values:', data['Flow Bytes/s'].isna().sum())\n",
    "print('Number of \\'Flow Packets/s\\' missing values:', data['Flow Packets/s'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e29b11f-052c-4920-a0f6-c214a4a3c0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BENIGN', 'DDoS', 'PortScan', 'Bot', 'Infiltration',\n",
       "       'Web Attack ï¿½ Brute Force', 'Web Attack ï¿½ XSS',\n",
       "       'Web Attack ï¿½ Sql Injection', 'FTP-Patator', 'SSH-Patator',\n",
       "       'DoS slowloris', 'DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye',\n",
       "       'Heartbleed'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24f397d-643a-46f8-8932-7a7907ef910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN                        2096484\n",
       "DoS Hulk                       172849\n",
       "DDoS                           128016\n",
       "PortScan                        90819\n",
       "DoS GoldenEye                   10286\n",
       "FTP-Patator                      5933\n",
       "DoS slowloris                    5385\n",
       "DoS Slowhttptest                 5228\n",
       "SSH-Patator                      3219\n",
       "Bot                              1953\n",
       "Web Attack ï¿½ Brute Force         1470\n",
       "Web Attack ï¿½ XSS                  652\n",
       "Infiltration                       36\n",
       "Web Attack ï¿½ Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of attacks & normal instances (BENIGN)\n",
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0fdbd7c-b5e1-4f0f-9ebd-4d2916128100",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_map = {\n",
    "    'BENIGN': 'BENIGN',\n",
    "    'DDoS': 'DDoS',\n",
    "    'DoS Hulk': 'DoS',\n",
    "    'DoS GoldenEye': 'DoS',\n",
    "    'DoS slowloris': 'DoS',\n",
    "    'DoS Slowhttptest': 'DoS',\n",
    "    'PortScan': 'Port Scan',\n",
    "    'FTP-Patator': 'Brute Force',\n",
    "    'SSH-Patator': 'Brute Force',\n",
    "    'Bot': 'Bot',\n",
    "    'Web Attack ï¿½ Brute Force': 'Web Attack',\n",
    "    'Web Attack ï¿½ XSS': 'Web Attack',\n",
    "    'Web Attack ï¿½ Sql Injection': 'Web Attack',\n",
    "    'Infiltration': 'Infiltration',\n",
    "    'Heartbleed': 'Heartbleed'\n",
    "}\n",
    "\n",
    "# Creating a new column 'Attack Type' in the DataFrame based on the attack_map dictionary\n",
    "data['Attack Type'] = data['Label'].map(attack_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8952b468-f629-4eb3-aeac-5e993399292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack Type\n",
       "BENIGN          2096484\n",
       "DoS              193748\n",
       "DDoS             128016\n",
       "Port Scan         90819\n",
       "Brute Force        9152\n",
       "Web Attack         2143\n",
       "Bot                1953\n",
       "Infiltration         36\n",
       "Heartbleed           11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Attack Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06436884-556c-451b-940b-a3ef562e5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Attack Type', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b597f05b-8ef7-4fc3-a2b8-524152c0c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
       "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
       "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
       "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
       "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
       "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
       "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
       "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
       "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
       "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
       "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
       "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
       "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
       "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
       "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
       "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
       "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
       "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
       "       'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
       "       'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
       "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
       "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
       "       'Idle Std', 'Idle Max', 'Idle Min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fc63c8b-c9d4-46cc-89b2-65194be8d951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0                   54865              3                  2   \n",
       "1                   55054            109                  1   \n",
       "2                   55055             52                  1   \n",
       "3                   46236             34                  1   \n",
       "4                   54863              3                  2   \n",
       "...                   ...            ...                ...   \n",
       "2830738                53          32215                  4   \n",
       "2830739                53            324                  2   \n",
       "2830740             58030             82                  2   \n",
       "2830741                53        1048635                  6   \n",
       "2830742                53          94939                  4   \n",
       "\n",
       "         Total Backward Packets  Flow Bytes/s  Flow Packets/s  SYN Flag Count  \\\n",
       "0                             0  4.000000e+06   666666.666700               0   \n",
       "1                             1  1.100917e+05    18348.623850               0   \n",
       "2                             1  2.307692e+05    38461.538460               0   \n",
       "3                             1  3.529412e+05    58823.529410               0   \n",
       "4                             0  4.000000e+06   666666.666700               0   \n",
       "...                         ...           ...             ...             ...   \n",
       "2830738                       2  8.194940e+03      186.248642               0   \n",
       "2830739                       2  1.376543e+06    12345.679010               0   \n",
       "2830740                       1  4.512195e+05    36585.365850               1   \n",
       "2830741                       2  4.272221e+02        7.628965               0   \n",
       "2830742                       2  4.360695e+03       63.198475               0   \n",
       "\n",
       "         ACK Flag Count  FIN Flag Count  \n",
       "0                     1               0  \n",
       "1                     1               0  \n",
       "2                     1               0  \n",
       "3                     1               0  \n",
       "4                     1               0  \n",
       "...                 ...             ...  \n",
       "2830738               0               0  \n",
       "2830739               0               0  \n",
       "2830740               1               0  \n",
       "2830741               0               0  \n",
       "2830742               0               0  \n",
       "\n",
       "[2522362 rows x 9 columns]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Selecting key network-related features for graph construction\n",
    "selected_features = [\"Destination Port\", \"Flow Duration\", \"Total Fwd Packets\", \"Total Backward Packets\",\"Flow Bytes/s\", \"Flow Packets/s\", \"SYN Flag Count\", \"ACK Flag Count\", \"FIN Flag Count\"]\n",
    "\n",
    "Analysis_data = data[selected_features]\n",
    "Analysis_data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47c63593-ffc4-451a-bb90-95651b1c62a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Anomalous Nodes (High PageRank): ['Flow_3.0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data to reduce processing time\n",
    "subset_data = Analysis_data.sample(n=5000)\n",
    "\n",
    "# Create a directed graph (Network Flow Graph)\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges based on network traffic patterns\n",
    "for _, row in subset_data.iterrows():\n",
    "    src = f\"SrcPort_{row['Destination Port']}\"\n",
    "    dst = f\"Flow_{row['Flow Duration']}\"\n",
    "    weight = row['Flow Bytes/s']\n",
    "    \n",
    "    G.add_edge(src, dst, weight=weight)\n",
    "\n",
    "# Convert to sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "adj_matrix = nx.to_scipy_sparse_array(G, weight='weight', dtype=float)\n",
    "\n",
    "\n",
    "# Compute centrality measures in parallel\n",
    "def compute_centrality(G, method):\n",
    "    if method == \"betweenness\":\n",
    "        return nx.betweenness_centrality(G, k=100)\n",
    "    elif method == \"closeness\":\n",
    "        return nx.closeness_centrality(G, wf_improved=True)\n",
    "    elif method == \"pagerank\":\n",
    "        return nx.pagerank(G, max_iter=50)\n",
    "\n",
    "results = Parallel(n_jobs=3)(delayed(compute_centrality)(G, method) for method in [\"betweenness\", \"closeness\", \"pagerank\"])\n",
    "\n",
    "betweenness, closeness, pagerank = results\n",
    "\n",
    "# Identify potential attack nodes (high centrality values)\n",
    "thresh = 0.01  # Threshold to detect anomalies\n",
    "attack_nodes = [node for node, score in pagerank.items() if score > thresh]\n",
    "\n",
    "print(\"Potential Anomalous Nodes (High PageRank):\", attack_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f62d40a8-97cc-4d52-acc4-d2756a437687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Source Nodes: 53805\n",
      "Unique Destination Nodes: 1050899\n",
      "Estimated Total Nodes: 1104704\n"
     ]
    }
   ],
   "source": [
    "unique_sources = Analysis_data['Destination Port'].nunique()\n",
    "unique_destinations = Analysis_data['Flow Duration'].nunique()\n",
    "print(\"Unique Source Nodes:\", unique_sources)\n",
    "print(\"Unique Destination Nodes:\", unique_destinations)\n",
    "print(\"Estimated Total Nodes:\", unique_sources + unique_destinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c790b5d7-aab0-408b-8ece-e97bf9dd4c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvis\n",
      "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from pyvis) (8.25.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from pyvis) (3.1.4)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Downloading jsonpickle-4.0.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: networkx>=1.11 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from pyvis) (3.2.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\juver\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\juver\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\juver\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\juver\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\juver\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\juver\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\juver\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "   ---------------------------------------- 0.0/756.0 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 41.0/756.0 kB 2.0 MB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 92.2/756.0 kB 880.9 kB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 225.3/756.0 kB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 614.4/756.0 kB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 686.1/756.0 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/756.0 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 756.0/756.0 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading jsonpickle-4.0.2-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.3/46.3 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: jsonpickle, pyvis\n",
      "Successfully installed jsonpickle-4.0.2 pyvis-0.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77f54885-e628-400d-ac15-f82c4d062147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "provenance_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"provenance_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23e30b23620>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a subgraph with the first 5000 nodes\n",
    "sample_nodes = list(G.nodes)[:5000]\n",
    "subG = G.subgraph(sample_nodes)\n",
    "\n",
    "net = Network(notebook=True, width=\"100%\", height=\"800px\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(subG)\n",
    "net.show(\"provenance_graph.html\")  # Opens in browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "203ff1de-5393-4d77-ae6d-04fe1c865eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SrcPort_53.0', 0.274748322147651),\n",
       " ('SrcPort_80.0', 0.22839765100671142),\n",
       " ('SrcPort_443.0', 0.1950503355704698),\n",
       " ('Flow_3.0', 0.024328859060402684),\n",
       " ('Flow_4.0', 0.013003355704697987),\n",
       " ('SrcPort_123.0', 0.009228187919463088),\n",
       " ('Flow_1.0', 0.006711409395973154),\n",
       " ('Flow_48.0', 0.004614093959731544),\n",
       " ('SrcPort_21.0', 0.004614093959731544),\n",
       " ('Flow_2.0', 0.004614093959731544)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality = nx.degree_centrality(G)\n",
    "sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:10]  # Top 10 influential nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b220b838-6012-48a0-99bb-ff2caa21043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SrcPort_53.0', 0.0),\n",
       " ('Flow_75574.0', 0.0),\n",
       " ('SrcPort_60343.0', 0.0),\n",
       " ('Flow_21573431.0', 0.0),\n",
       " ('Flow_61748.0', 0.0),\n",
       " ('SrcPort_443.0', 0.0),\n",
       " ('Flow_5590616.0', 0.0),\n",
       " ('SrcPort_80.0', 0.0),\n",
       " ('Flow_115931856.0', 0.0),\n",
       " ('Flow_31296.0', 0.0)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betweenness = nx.betweenness_centrality(G)\n",
    "sorted(betweenness.items(), key=lambda x: x[1], reverse=True)[:10]  # Top influential nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8e71028-40bd-494e-ae1a-cee08e946d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Nodes by Degree Centrality: [('SrcPort_53.0', 0.274748322147651), ('SrcPort_80.0', 0.22839765100671142), ('SrcPort_443.0', 0.1950503355704698), ('Flow_3.0', 0.024328859060402684), ('Flow_4.0', 0.013003355704697987), ('SrcPort_123.0', 0.009228187919463088), ('Flow_1.0', 0.006711409395973154), ('Flow_48.0', 0.004614093959731544), ('SrcPort_21.0', 0.004614093959731544), ('Flow_2.0', 0.004614093959731544)]\n",
      "Top 10 Nodes by Betweenness Centrality: [('SrcPort_53.0', 0.0), ('Flow_75574.0', 0.0), ('SrcPort_60343.0', 0.0), ('Flow_21573431.0', 0.0), ('Flow_61748.0', 0.0), ('SrcPort_443.0', 0.0), ('Flow_5590616.0', 0.0), ('SrcPort_80.0', 0.0), ('Flow_115931856.0', 0.0), ('Flow_31296.0', 0.0)]\n",
      "Top 10 Nodes by Closeness Centrality: [('Flow_3.0', 0.024328859060402684), ('Flow_4.0', 0.013003355704697987), ('Flow_1.0', 0.006711409395973154), ('Flow_48.0', 0.004614093959731544), ('Flow_2.0', 0.004614093959731544), ('Flow_54.0', 0.003984899328859061), ('Flow_49.0', 0.0037751677852348995), ('Flow_53.0', 0.0035654362416107383), ('Flow_51.0', 0.003355704697986577), ('Flow_50.0', 0.003145973154362416)]\n",
      "Top 10 Nodes by PageRank: [('Flow_3.0', 0.016866925453588946), ('Flow_4.0', 0.008968439841346876), ('Flow_1.0', 0.004795631592915139), ('Flow_2.0', 0.0032308372735086978), ('Flow_48.0', 0.003044552235484121), ('Flow_54.0', 0.002858130348946763), ('Flow_49.0', 0.002411183106200562), ('Flow_51.0', 0.002411183106200562), ('Flow_53.0', 0.0023502404904373725), ('Flow_17.0', 0.0022620182272681186)]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Degree Centrality (Number of connections per node)\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Betweenness Centrality (Nodes acting as 'bridges' between clusters)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "# Closeness Centrality (Nodes that quickly reach others)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# PageRank (Identifies influential nodes)\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Sort nodes by highest centrality scores\n",
    "top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Display top 10 nodes for each measure\n",
    "print(\"Top 10 Nodes by Degree Centrality:\", top_degree)\n",
    "print(\"Top 10 Nodes by Betweenness Centrality:\", top_betweenness)\n",
    "print(\"Top 10 Nodes by Closeness Centrality:\", top_closeness)\n",
    "print(\"Top 10 Nodes by PageRank:\", top_pagerank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ef4f3cc-186d-454d-a4ed-c694f1f4a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Degree-Based Anomalous Nodes: ['SrcPort_53.0', 'SrcPort_443.0', 'SrcPort_80.0', 'Flow_3.0']\n",
      "ðŸš¨ Betweenness-Based Anomalous Nodes: []\n",
      "ðŸš¨ Closeness-Based Anomalous Nodes: ['Flow_43.0', 'Flow_3.0', 'Flow_64.0', 'Flow_48.0', 'Flow_58.0', 'Flow_49.0', 'Flow_55.0', 'Flow_53.0', 'Flow_50.0', 'Flow_72.0', 'Flow_97.0', 'Flow_66.0', 'Flow_1.0', 'Flow_29.0', 'Flow_4.0', 'Flow_57.0', 'Flow_2.0', 'Flow_70.0', 'Flow_16.0', 'Flow_45.0', 'Flow_51.0', 'Flow_75.0', 'Flow_47.0', 'Flow_26.0', 'Flow_54.0', 'Flow_46.0', 'Flow_62.0', 'Flow_63.0', 'Flow_60.0', 'Flow_56.0', 'Flow_52.0', 'Flow_24.0', 'Flow_83.0', 'Flow_34.0', 'Flow_17.0', 'Flow_65.0']\n",
      "ðŸš¨ PageRank-Based Anomalous Nodes: ['Flow_3.0', 'Flow_64.0', 'Flow_48.0', 'Flow_58.0', 'Flow_49.0', 'Flow_38.0', 'Flow_55.0', 'Flow_53.0', 'Flow_50.0', 'Flow_72.0', 'Flow_97.0', 'Flow_66.0', 'Flow_1.0', 'Flow_29.0', 'Flow_4.0', 'Flow_57.0', 'Flow_2.0', 'Flow_70.0', 'Flow_45.0', 'Flow_51.0', 'Flow_75.0', 'Flow_47.0', 'Flow_26.0', 'Flow_54.0', 'Flow_46.0', 'Flow_62.0', 'Flow_63.0', 'Flow_60.0', 'Flow_40.0', 'Flow_56.0', 'Flow_52.0', 'Flow_24.0', 'Flow_34.0', 'Flow_17.0', 'Flow_65.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juver\\AppData\\Local\\Temp\\ipykernel_23904\\3102991601.py:13: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  anomalies = [node for node, val in zip(G.nodes, values) if (val - mean) / std > threshold]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert centrality values to numpy arrays\n",
    "degree_vals = np.array(list(degree_centrality.values()))\n",
    "betweenness_vals = np.array(list(betweenness_centrality.values()))\n",
    "closeness_vals = np.array(list(closeness_centrality.values()))\n",
    "pagerank_vals = np.array(list(pagerank.values()))\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "def detect_anomalies(values, threshold=3):\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    anomalies = [node for node, val in zip(G.nodes, values) if (val - mean) / std > threshold]\n",
    "    return anomalies\n",
    "\n",
    "# Identify anomalous nodes\n",
    "degree_anomalies = detect_anomalies(degree_vals)\n",
    "betweenness_anomalies = detect_anomalies(betweenness_vals)\n",
    "closeness_anomalies = detect_anomalies(closeness_vals)\n",
    "pagerank_anomalies = detect_anomalies(pagerank_vals)\n",
    "\n",
    "print(\"ðŸš¨ Degree-Based Anomalous Nodes:\", degree_anomalies)\n",
    "print(\"ðŸš¨ Betweenness-Based Anomalous Nodes:\", betweenness_anomalies)\n",
    "print(\"ðŸš¨ Closeness-Based Anomalous Nodes:\", closeness_anomalies)\n",
    "print(\"ðŸš¨ PageRank-Based Anomalous Nodes:\", pagerank_anomalies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac36fcc3-5a67-4eee-b6a8-f729efcb3874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "intrusion_detection_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"intrusion_detection_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23e2d1c4350>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, width=\"100%\", height=\"800px\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "# Add nodes and color anomalies\n",
    "for node in G.nodes:\n",
    "    color = \"white\"\n",
    "    if node in degree_anomalies or node in betweenness_anomalies or node in pagerank_anomalies:\n",
    "        color = \"red\"  # Mark anomalies in red\n",
    "    net.add_node(node, label=node, color=color)\n",
    "\n",
    "# Add edges\n",
    "for edge in G.edges:\n",
    "    net.add_edge(edge[0], edge[1])\n",
    "\n",
    "# Save and view\n",
    "net.show(\"intrusion_detection_graph.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51683706-e35b-4bc6-9e00-06c6426f05e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
